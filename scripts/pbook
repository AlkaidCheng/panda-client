#!/bin/bash

"exec" "/usr/bin/python" "-u" "-Wignore" "$0" "$@"

# using /usr/bin/python for pyGTK 

import re
import os
import sys
import code
import time
import atexit
import signal
import datetime
import tempfile
import commands

# tweak sys.path since threading cannot be imported with Athena 15 on SLC5/64
tmpOut = commands.getoutput('unset LD_LIBRARY_PATH; unset PYTHONPATH; /usr/bin/python -c "import sys;print sys.path"')
try:
    exec "tmpSysPath = %s" % tmpOut.split('\n')[-1]
    sys.path = tmpSysPath + sys.path
except:
    pass

import optparse
import readline
import threading

from pandatools import PdbUtils
from pandatools import Client
from pandatools import BookConfig
from pandatools import GlobalConfig
from pandatools import PLogger
from pandatools import PsubUtils
from pandatools import PandaToolsPkgInfo


# readline support
readline.parse_and_bind('tab: complete')
readline.parse_and_bind('set show-all-if-ambiguous On')

# history support
pconfDir = os.path.expanduser(os.environ['PANDA_CONFIG_ROOT'])
if not os.path.exists(pconfDir):
    os.makedirs(pconfDir)
historyFile = '%s/.history' % pconfDir
# history file
if os.path.exists(historyFile):
    readline.read_history_file(historyFile)
readline.set_history_length(1024)

# set dummy CMTSITE
if not os.environ.has_key('CMTSITE'):
    os.environ['CMTSITE'] = ''

# set grid source file
globalConf = GlobalConfig.getConfig()
if globalConf.grid_src != '' and not os.environ.has_key('PATHENA_GRID_SETUP_SH'):
    os.environ['PATHENA_GRID_SETUP_SH'] = globalConf.grid_src

# make tmp dir
tmpDir = tempfile.mkdtemp()

# set tmp dir in Client
Client.setGlobalTmpDir(tmpDir)

# fork PID 
fork_child_pid = None

# exit action
def _onExit(dirName,hFile):
    # save history only for master process
    if fork_child_pid == 0:
        readline.write_history_file(hFile)
    # remove tmp dir
    commands.getoutput('rm -rf %s' % dirName)
atexit.register(_onExit,tmpDir,historyFile)



# look for PandaTools package
for path in sys.path:
    if path == '':
        path = '.'
    if os.path.exists(path) and 'pandatools' in os.listdir(path):
        # make symlink for module name
        os.symlink('%s/pandatools' % path,'%s/taskbuffer' % tmpDir)
        break
sys.path = [tmpDir]+sys.path



# core class for book keeping
class PBookCore:

    # constructor
    def __init__(self,enforceEnter=False,verbose=False):
        # verbose
        self.verbose = verbose
        # initialize database
        PdbUtils.initialzieDB(self.verbose)
        # check proxy
        self.gridPassPhrase,self.vomsFQAN = PsubUtils.checkGridProxy('',enforceEnter,self.verbose)


    # synchronize database
    def sync(self):
        # get logger
        tmpLog = PLogger.getPandaLogger()
        tmpLog.info("Synchronizing local repository ...")
        # check proxy
        self.gridPassPhrase,self.vomsFQAN = PsubUtils.checkGridProxy(self.gridPassPhrase,False,self.verbose)
        # get JobIDs in local repository
        localJobIDs = PdbUtils.getListOfJobIDs()
        # get recent JobIDs from panda server
        syncTime = datetime.datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')
        # set sync time for the first attempt
        bookConf = BookConfig.getConfig()
        if bookConf.last_synctime == '':
            bookConf.last_synctime = datetime.datetime.utcnow()-datetime.timedelta(days=180)
            bookConf.last_synctime = bookConf.last_synctime.strftime('%Y-%m-%d %H:%M:%S')
        status,remoteJobIDs = Client.getJobIDsInTimeRange(bookConf.last_synctime,verbose=self.verbose)
        if status != 0:
            tmpLog.error("Failed to get JobIDs from panda server")
            return
        tmpLog.info("Got %s jobs to be updated" % len(remoteJobIDs))
        # insert if missing
        for remoteJobID in remoteJobIDs:
            # check local status
            job = None
            if remoteJobID in localJobIDs:
                # get job info from local repository
                job = PdbUtils.readJobDB(remoteJobID,self.verbose)
                # skip if frozen
                if job.dbStatus == 'frozen':
                    continue
            tmpLog.info("Updating JobID=%s ..." % remoteJobID)
            # get PandaIDs
            status,pandaIDstatus = Client.getPandIDsWithJobID(remoteJobID,verbose=self.verbose)
            if status != 0:
                tmpLog.error("Failed to get PandaIDs for %s" % remoteJobID) 
                return
            pandaIDs = pandaIDstatus.keys()
            pandaIDs.sort()
            # get full JobSpec
            pandaJobs = []            
            pandaFileInfo = {}
            if job == None:
		tmpIDs = [pandaIDs[0],pandaIDs[-1]]
                status,pandaJobs = Client.getFullJobStatus(tmpIDs,verbose=self.verbose)
                if status != 0:
                    tmpLog.error("Failed to get PandaIDs for %s" % remoteJobID) 
                    return
		# get slimmed file info
                status,pandaFileInfo = Client.getSlimmedFileInfoPandaIDs(pandaIDs,verbose=self.verbose)
                if status != 0:
                    tmpLog.error("Failed to get file info  for %s" % remoteJobID)
                    return
            # convert to local job spec
            localJob = PdbUtils.convertPtoD(pandaJobs,pandaIDstatus,job,pandaFileInfo)
            # update database 
            if not remoteJobID in localJobIDs:
                # insert to DB
                try:
                    PdbUtils.insertJobDB(localJob,self.verbose)
                except:
                    tmpLog.error("Failed to insert JobID=%s to local repository" % remoteJobID)
                    return
                # set retryID
                if not localJob.provenanceID in [0,'0']:
                    try:
                        PdbUtils.setRetryID(localJob,self.verbose)
                    except:
                        tmpLog.error("Failed to set retryID for JobID=%s in local repository" % remoteJobID)
                        return
            else:
                # update
                try:
                    PdbUtils.updateJobDB(localJob,self.verbose)
                except:
                    tmpLog.error("Failed to update local repository for JobID=%s" % remoteJobID)
                    return
        # update sync time
        bookConf = BookConfig.getConfig()
        bookConf.last_synctime = syncTime
        BookConfig.updateConfig(bookConf)
        tmpLog.info("Synchronization Completed")
        

    # get local job info
    def getJobInfo(self,JobID):
        # get logger
        tmpLog = PLogger.getPandaLogger()
        # get job info from local repository
        job = PdbUtils.readJobDB(JobID,self.verbose)
        # not found
        if job == None:
            tmpLog.warning("JobID=%s not found in local repository. Synchronization may be needed" % JobID)
            return None
        # return
        return job


    # get local job list
    def getLocalJobList(self):
        # get jobs
        localJobs = PdbUtils.bulkReadJobDB(self.verbose)
        # return
        return localJobs
    
        
    # get status
    def status(self,JobID,forceUpdate=False):
        # get logger
        tmpLog = PLogger.getPandaLogger()
        # check proxy
        self.gridPassPhrase,self.vomsFQAN = PsubUtils.checkGridProxy(self.gridPassPhrase,False,self.verbose)
        # get job info from local repository
        job = self.getJobInfo(JobID)
        if job == None:
            tmpLog.warning("JobID=%s not found in local repository. Synchronization may be needed" % JobID)            
            return None
        # update if needed
        if job.dbStatus != 'frozen' or forceUpdate:
            tmpLog.info("Getting status for JobID=%s ..." % JobID)            
            # get status from Panda server
            status,pandaIDstatus = Client.getPandIDsWithJobID(JobID,
                                                              nJobs=len(job.PandaID.split(',')),
                                                              verbose=self.verbose)
            if status != 0:
                tmpLog.error("Failed to get status for JobID=%s" % JobID)
                return None
            # convert to local job spec
            job = PdbUtils.convertPtoD([],pandaIDstatus,job)
            # update DB
            try:
                PdbUtils.updateJobDB(job,self.verbose)
            except:
                tmpLog.error("Failed to update local repository for JobID=%s" % JobID)
                return None
            tmpLog.info("Updated JobID=%s" % JobID)                        
        # return
        return job


    # kill
    def kill(self,JobID):
        # get logger
        tmpLog = PLogger.getPandaLogger()
        # check proxy
        self.gridPassPhrase,self.vomsFQAN = PsubUtils.checkGridProxy(self.gridPassPhrase,False,self.verbose)
        # get job info from local repository
        job = self.getJobInfo(JobID)
        if job == None:
            tmpLog.warning("JobID=%s not found in local repository. Synchronization may be needed" % JobID)            
            return None
	# skip frozen job
        if job.dbStatus == 'frozen':
            tmpLog.info('All subJobs already finished/failed')
            return
        # get PandaID list
        killJobs = job.PandaID.split(',')
        # kill
        tmpLog.info('Sending kill command ...')
        status,output = Client.killJobs(killJobs,self.verbose)
        if status != 0:
            tmpLog.error(output)
            tmpLog.error("Failed to kill JobID=%s" % JobID)
            return
        # update database
        job.commandToPilot = 'tobekilled'
        # update DB
        try:
            PdbUtils.updateJobDB(job,self.verbose)
        except:
            tmpLog.error("Failed to update local repository for JobID=%s" % JobID)
            return
        # done
        tmpLog.info('Done. JobID=%s will be killed in 30min' % JobID)
        return


    # retry
    def retry(self,JobID):
        # get logger
        tmpLog = PLogger.getPandaLogger()
        # check proxy
        self.gridPassPhrase,self.vomsFQAN = PsubUtils.checkGridProxy(self.gridPassPhrase,False,self.verbose)
        # get job info from local repository
        localJob = self.getJobInfo(JobID)
        if localJob == None:
            tmpLog.warning("JobID=%s not found in local repository. Synchronization may be needed" % JobID)            
            return None
	# skip running job
        if localJob.dbStatus != 'frozen':
            tmpLog.warning('Cannot retry running jobs')
            return
	# skip already retried
        if localJob.retryID != '0':
            tmpLog.warning('This job was already retried by JobID=%s' % localJob.retryID)
            return
        # check status of buildJob
        if not localJob.buildStatus in ['','finished']:
            tmpLog.warning('Cannot retry when status of buildJob %s is %s (!= finished)' \
                           % (localJob.PandaID.split(',')[0],localJob.buildStatus))
            return
        # get list of failed jobs
        pandaIDs  = localJob.PandaID.split(',')
        statusList= localJob.jobStatus.split(',')
        jobList = []
        for idx in range(len(pandaIDs)):
            # check status
            if statusList[idx] != 'failed':
                continue
            jobList.append(pandaIDs[idx])
        # no failed job
        if jobList == []:
            tmpLog.info('No failed jobs to be retried for %s' % JobID)
            return
        # get full job spec
        tmpLog.info("Retrying JobID=%s ..." % JobID)
        tmpLog.info("Getting job info")
        idxJL  = 0
        nQuery = 500
        pandaJobs = []
        while idxJL < len(jobList):
            # avoid burst query
            tmpLog.info(" %5s/%s" % (idxJL,len(jobList)))                
            status,oTmp = Client.getFullJobStatus(jobList[idxJL:idxJL+nQuery],
                                                  verbose=self.verbose)
            if status != 0:
                tmpLog.error(status)
                tmpLog.error(oTmp)
                tmpLog.error("Cannot get job info from Panda server")
                return
            pandaJobs += oTmp
            idxJL += nQuery
            time.sleep(1)
        tmpLog.info(" %5s/%s" % (len(jobList),len(jobList)))            
        # reset some parameters
        retryJobs    = []
        retrySite    = None
        retryElement = None
        retryDestSE  = None
        for idx in range(len(jobList)):
            job = pandaJobs[idx]
            # skip exired
            if job == None:
                tmpLog.warning("Could not retry jobs older than 30 days : JobID=%s (PandaID=%s) expired" \
                               % (JobID,jobList[idxJob]))
                return
            # unify sitename
            if retrySite == None:
                retrySite    = job.computingSite
                retryElement = job.computingElement
                retryDestSE  = job.destinationSE
            # reset
            job.jobStatus           = None
            job.commandToPilot      = None
            job.startTime           = None
            job.endTime             = None
            job.attemptNr           = 1+job.attemptNr
            for attr in job._attributes:
                if attr.endswith('ErrorCode') or attr.endswith('ErrorDiag'):
                    setattr(job,attr,None)
            job.transExitCode       = None
            job.computingSite       = retrySite
            job.computingElement    = retryElement
            job.destinationSE       = retryDestSE
            job.dispatchDBlock      = None
            job.jobExecutionID      = JobID
            for file in job.Files:
                file.rowID = None
                if file.type == 'input':
                    file.status = 'ready'
                elif file.type in ('output','log'):
                    file.destinationSE = retryDestSE
                    file.destinationDBlock=file.dataset
                    # add attempt nr
                    oldName  = file.lfn
                    file.lfn = re.sub("\.\d+$","",file.lfn)
                    file.lfn = "%s.%d" % (file.lfn,job.attemptNr)
                    newName  = file.lfn
                    # modify jobParameters
                    job.jobParameters = re.sub("'%s'" % oldName ,"'%s'" % newName,
                                               job.jobParameters)
                    # look for output in trf
                    oldGenelicName = re.sub('\.\d+$','',oldName)
                    match = re.search(oldGenelicName+'(\.\d+)*(%20|")',job.jobParameters)
                    if match != None:
                        job.jobParameters = job.jobParameters.replace(match.group(0),newName+match.group(2))
            # append
            retryJobs.append(job)
        # submit
        tmpLog.info("Submitting job ...")            
        status,out = Client.submitJobs(retryJobs,verbose=self.verbose)
        if out == None or status != 0:
            tmpLog.error(status)
            tmpLog.error(out)
            tmpLog.error("Failed to submit jobs to Panda server")
            return
        # update database
        pandaIDstatus = {}
        newJobID = None
        for items in out:
            # get newJobID
            if newJobID == None:
                newJobID = items[1]
            # check PandaID
            PandaID = items[0]
            if PandaID == 'NULL':
                tmpLog.error("Panda server returned wrong IDs. It may have a temporary problem")
                return
            # dummy statuso
            pandaIDstatus[PandaID] = ('defined','NULL')
        # set retry ID
        localJob.retryID = newJobID
        try:
            PdbUtils.updateJobDB(localJob,self.verbose)
        except:
            tmpLog.error("Failed to set retryID for JobID=%s" % JobID)
            return
        # set new paramers
        newLocalJob = PdbUtils.convertPtoD(retryJobs,pandaIDstatus)
        newLocalJob.JobID = newJobID
        newLocalJob.creationTime = datetime.datetime.utcnow()
        # insert to DB
        try:
            PdbUtils.insertJobDB(newLocalJob,self.verbose)
        except:
            tmpLog.error("Failed to insert JobID=%s to local repository" % newJobID)
            return
        # done
        tmpLog.info('Done. New JobID=%s' % newJobID)
            


# keep original help
_orgHelp = help



# main for interactive session
def intmain(pbookCore,comString):

    # help
    def help(*arg):
        """Print help"""
        # use built-in help
        if len(arg) > 0:
            apply(_orgHelp,arg)
            return
        # print available methods
        str = """The following commands are available:

   sync
   show
   kill
   retry
         
For more info, do help(show) for example."""
        print str
        
                                        
    # show status
    def show(JobID=None,forceUpdate=False):
        """Print job records. All jobs will be shown if JobID is omitted. Only running jobs and last N jobs will be shown if show('running') and show(-N), respectively.
        
         example:
           >>> show()
           >>> show(12)
           >>> show(-5)
           >>> show('running')
         """
        if JobID == None or JobID < 0:
            # show all local info
            jobList = pbookCore.getLocalJobList()
            if JobID < 0:
                jobList = jobList[JobID:]
            # print
            for job in jobList:
                print "======================================"
                print job
	elif JobID == 'running':
            # show runnig jobs
            jobList = pbookCore.getLocalJobList()
	    for job in jobList:
                if job.dbStatus != 'frozen':
                    show(job.JobID)
        else:
            job = pbookCore.status(JobID,forceUpdate)
            # print
            print "======================================"
            print job


    # kill
    def kill(JobID):
        """Kill all subJobs in JobID

         example:
           >>> kill(15)
        """
        pbookCore.kill(JobID)


    # retry
    def retry(JobID,upperJobID=None):
        """Retry failed subJobs in JobID. Jobs between JobID and UpperJobID will be retried if upperJobID is given

         example:
           >>> retry(15)
           >>> retry(15,20)
        """
        if upperJobID != None:
            # check range
            if JobID > upperJobID:
                tmpLog = PLogger.getPandaLogger()
                tmpLog.error("upper JobID must be larger than %s" % JobID)
            else:
                # retry jobs between the range
                for tmpJobID in range(JobID,upperJobID+1):
                    pbookCore.retry(tmpJobID)
        else:            
            pbookCore.retry(JobID)


    # synchronize local repository
    def sync():
        """Synchronize local repository

         example:
           >>> sync()
        """
        pbookCore.sync()


    # execut command in the batch mode
    if comString != '':
        try:
            # decompose to function name and argument
            match = re.search('^([^\(]+)\((\d*)\)$',comString)
            comName = match.group(1)
            comArg  = match.group(2)
            if comArg != '':
                # convert to int
                comArg = (long(comArg),)
            else:
                # for functions without arguments
                comArg = ()
            # exec : exec cannot be used due to unqualified exec with nested functions
            apply(locals()[comName],comArg)
        except:
            pass
        # exit
        sys.exit(0)
    # run sync
    pbookCore.sync()
    # go to interactive prompt
    code.interact(banner="\nStart pBook %s" % PandaToolsPkgInfo.release_version,
                  local=locals())


# main for GUI session
def guimain(pbookCore):
    import gtk
    from pandatools import BookGUI
    pbookGuiMain = BookGUI.PBookGuiMain(pbookCore)
    # get logger
    tmpLog = PLogger.getPandaLogger()
    tmpLog.info("Start pBook %s" % PandaToolsPkgInfo.release_version)
    # GTK main
    gtk.main()
    

# kill whole process
def catch_sig(sig, frame):
    # cleanup
    _onExit(tmpDir,historyFile)
    # kill
    commands.getoutput('kill -9 -- -%s' % os.getpgrp())


# overall main
if __name__ == "__main__":

    # parse option
    parser = optparse.OptionParser()
    parser.add_option("-v",action="store_true",dest="verbose",default=False,
                      help="verbose")
    parser.add_option("--gui",action="store_true",dest="gui",default=False,
                      help="use GUI")
    parser.add_option('-c',action='store',dest='comString',default='',type='string',
                      help='execute a command in the batch mode')
    parser.add_option("--noPass",action="store_true",dest="noPass",default=False,
                      help="disable to enter pass phrase for GUI")
    parser.add_option('--version',action='store_const',const=True,dest='version',default=False,
                      help='Displays version')
    parser.add_option('--devSrv',action='store_const',const=True,dest='devSrv',default=False,
                      help="Please don't use this option. Only for developers to use the dev panda server")
    
    options,args = parser.parse_args()

    # display version
    if options.version:
        print "Version: %s" % PandaToolsPkgInfo.release_version
        sys.exit(0)

    # use dev server
    if options.devSrv:
        Client.useDevServer()

    # fork for Ctl-c
    fork_child_pid = os.fork()
    if fork_child_pid == -1:
        print "ERROR : Failed to fork"
        sys.exit(1)
    if fork_child_pid == 0:
        # main
        if options.gui:
            # instantiate core with pass phrase
            if options.noPass:
                pbookCore = PBookCore(False,options.verbose)
            else:
                pbookCore = PBookCore(True,options.verbose)                
            # GUI
            guimain(pbookCore)
        else:
            # instantiate core
            pbookCore = PBookCore(False,options.verbose)
            # CUI
            intmain(pbookCore,options.comString)
    else:
        # set handler
        signal.signal(signal.SIGINT, catch_sig)
        signal.signal(signal.SIGHUP, catch_sig)
        signal.signal(signal.SIGTERM,catch_sig)
        os.wait()
    
